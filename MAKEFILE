# Default .env location
ENV_FILE=.env

# Command: make up
up: check-env setup-dirs build init
	@echo "ðŸš€ Starting Airflow stack with .env configuration..."
	docker compose up -d

# Command: make down
down:
	@echo "ðŸ›‘ Stopping Airflow stack..."
	docker compose down

# Command: make restart
restart: down up

# Command: make logs
logs:
	docker compose logs -f

# Command: make test
test:
	@echo "ðŸ§ª Running pytest data quality checks..."
	docker compose exec airflow-worker pytest tests/

# Build Airflow images
build:
	@echo "ðŸ”¨ Building Airflow images..."
	docker compose build

# Initialize Airflow
init:
	@echo "âš™ï¸ Checking if Airflow DB is already initialized..."
	@if docker compose exec -T postgres psql -U airflow -d airflow -c '\dt' >/dev/null 2>&1; then \
		echo "âœ… Airflow DB already initialized, skipping init."; \
	else \
		echo "ðŸ”§ Initializing Airflow database and users..."; \
		docker compose run --rm airflow-init; \
	fi

# Ensure required folders exist with correct ownership
setup-dirs:
	@echo "ðŸ“‚ Creating and fixing permissions for data/ and output/..."
	mkdir -p data output
	@if [ "$$(uname)" != "Linux" ]; then \
	  echo "âš ï¸ Skipping chown (not needed on Windows/macOS)"; \
	else \
	  sudo chown -R 50000:0 data output; \
	fi

# Ensure .env exists
check-env:
	@if [ ! -f $(ENV_FILE) ]; then \
		echo "âš™ï¸  .env not found, creating one..."; \
		read -p 'Enter your OpenWeather API key: ' APIKEY; \
		echo "AIRFLOW_UID=50000" > $(ENV_FILE); \
		echo "AIRFLOW_GID=0" >> $(ENV_FILE); \
		echo "OPENWEATHER_API_KEY=$$APIKEY" >> $(ENV_FILE); \
		echo ".env file created âœ…"; \
	else \
		echo "âœ… Using existing .env"; \
	fi